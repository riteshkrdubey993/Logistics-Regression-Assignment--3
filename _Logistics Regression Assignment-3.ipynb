{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32cf327b-4b36-4805-8abc-9a8f1f134ce9",
   "metadata": {},
   "source": [
    "# Q1. Explain the concept of precision and recall in the context of classification models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1285d41a-3980-4cad-a09d-b3908f577d7c",
   "metadata": {},
   "source": [
    "Precision and recall are two important performance metrics used to evaluate the effectiveness of classification models, particularly in situations where class imbalance exists. These metrics are particularly useful in cases where the cost of false positives and false negatives differs.\n",
    "\n",
    "Precision measures the accuracy of positive predictions made by the model. It quantifies the model's ability to avoid making false positive predictions. Precision is calculated as:\n",
    "\n",
    "$ Precision=  \\frac{TruePositives(TP)}{TruePositives(TP)+FalsePositives(FP)}$\n",
    "\n",
    "    True Positives (TP) are cases where the model correctly predicted positive instances.\n",
    "    False Positives (FP) are cases where the model incorrectly predicted positive instances when they were actually negative.\n",
    "\n",
    "\n",
    "In simpler terms, precision answers the question: \"Of all the instances predicted as positive, how many were actually positive?\" High precision indicates that when the model predicts a positive outcome, it is usually correct, and there are fewer false positive errors.\n",
    "\n",
    "Recall, also known as sensitivity or true positive rate, measures the model's ability to identify all positive instances correctly. It quantifies the model's ability to avoid false negative predictions. Recall is calculated as:\n",
    "\n",
    "$Recall= \\frac{TruePositives(TP)}{TruePositives(TP)+FalseNegatives(FN)}$\n",
    "​\n",
    " \n",
    "\n",
    "    True Negatives (TP) are cases where the model correctly predicted negative instances.\n",
    "    False Negatives (FN) are cases where the model incorrectly predicted negative instances when they were actually positive.\n",
    "In simpler terms, recall answers the question: \"Of all the actual positive instances, how many were correctly predicted as positive?\" High recall indicates that the model is effective at capturing most positive instances and minimizing false negatives."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d15c7a-e5e6-4e67-9117-c1c364cd951c",
   "metadata": {},
   "source": [
    "# Q2. What is the F1 score and how is it calculated? How is it different from precision and recall?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75dcc7c8-94de-41cd-b9e0-7a995b400372",
   "metadata": {},
   "source": [
    "The F1 score is a single metric that combines both precision and recall into one value, providing a balanced measure of a classification model's performance. It is particularly useful when you want to consider both false positives and false negatives simultaneously. The F1 score is calculated as the harmonic mean of precision and recall:\n",
    "\n",
    "$F1-Score= \\frac{2⋅(Precision⋅Recall)}{Precision+Recall}$\n",
    " \n",
    "    Precision measures the accuracy of positive predictions made by the model, emphasizing the avoidance of false positive errors.\n",
    "    Recall measures the model's ability to correctly identify all positive instances, emphasizing the avoidance of false negative errors.\n",
    "\n",
    "The harmonic mean ensures that the F1 score is closer to the smaller of precision and recall. This means that the F1 score is more sensitive to imbalances between precision and recall than other metrics. If either precision or recall is very low, the F1 score will also be low, reflecting the model's limitations in both areas.\n",
    "\n",
    "Differences between Precision, Recall, and F1-Score:\n",
    "\n",
    "1. Precision: Precision is focused on minimizing false positive errors, making it particularly useful when you want to be confident that a positive prediction is correct. It answers the question, \"Of all the instances predicted as positive, how many were actually positive?\"\n",
    "2. Recall: Recall is focused on minimizing false negative errors and is suitable when you want to capture as many positive instances as possible. It answers the question, \"Of all the actual positive instances, how many were correctly predicted as positive?\"\n",
    "3. F1-Score: The F1 score balances precision and recall. It is particularly useful when you want to achieve a compromise between precision and recall and when false positives and false negatives have different consequences. It provides a single metric to assess overall classification model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de182d2-a1f4-405f-ae5a-6b614dd32880",
   "metadata": {},
   "source": [
    "# Q3. What is ROC and AUC, and how are they used to evaluate the performance of classification models?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1841737-e87e-44a4-8f0b-ad3bb5bd86cf",
   "metadata": {},
   "source": [
    "ROC (Receiver Operating Characteristic) and AUC (Area Under the Curve) are tools used to evaluate the performance of classification models, particularly binary classification models. They help assess a model's ability to discriminate between positive and negative classes and make informed decisions about its classification threshold.\n",
    "\n",
    "### Receiver Operating Characteristic (ROC):\n",
    "\n",
    "1. The ROC curve is a graphical representation of a classification model's performance across different classification thresholds.\n",
    "2. It plots the True Positive Rate (TPR or Recall) against the False Positive Rate (FPR) at various threshold settings.\n",
    "3. TPR is the proportion of true positive predictions out of all actual positive instances (TP / (TP + FN)).\n",
    "4. FPR is the proportion of false positive predictions out of all actual negative instances (FP / (FP + TN)).\n",
    "\n",
    "A typical ROC curve shows the trade-off between true positive and false positive rates as the classification threshold varies. A steeper curve, which rises faster, suggests better model performance. The diagonal line from (0, 0) to (1, 1) represents random guessing, so the model's curve should be above this line to indicate predictive power.\n",
    "\n",
    "### Area Under the Curve (AUC):\n",
    "\n",
    "1. The AUC measures the overall performance of a classification model by calculating the area under the ROC curve.\n",
    "2. The AUC score ranges from 0 to 1, with higher values indicating better model discrimination.\n",
    "3. An AUC of 0.5 suggests random guessing (no discrimination), while an AUC of 1 indicates perfect discrimination.\n",
    "\n",
    "ROC and AUC uses following techniques to evaluate classification models:\n",
    "\n",
    "1. Model Comparison: ROC curves and AUC scores allow you to compare multiple models. The model with a higher AUC generally has better overall discrimination performance.\n",
    "2. Threshold Selection: By examining the ROC curve, you can choose an appropriate classification threshold that balances the trade-off between true positives and false positives based on the specific needs of your application.\n",
    "3. Model Robustness: A wide and well-separated ROC curve with a high AUC suggests that the model's performance is robust and consistent across various classification thresholds.\n",
    "4. Performance Assessment: ROC and AUC provide a global performance assessment that is less sensitive to class imbalances compared to precision and recall, making them particularly useful in imbalanced datasets.\n",
    "5. Diagnostics: ROC curves help diagnose the model's ability to handle different levels of sensitivity and specificity, which can be important in various applications, such as medical diagnostics and fraud detection."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab07baa4-88ad-4842-ade3-2f41d9085276",
   "metadata": {},
   "source": [
    "# Q4. How do you choose the best metric to evaluate the performance of a classification model? What is multiclass classification and how is it different from binary classification?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a8da486-fc22-4742-ae38-79266b940254",
   "metadata": {},
   "source": [
    "Choosing the best metric to evaluate the performance of a classification model depends on several factors, including the specific problem, the nature of the data, and the relative importance of minimizing false positives and false negatives. Here are some steps to guide metric selection:\n",
    "\n",
    "1. Understand the Problem:Gain a deep understanding of the problem you are solving and the domain in which the model will be used. Consider the consequences of both false positives and false negatives in the context of the application.\n",
    "2. Consider Class Imbalance:Determine if the dataset is imbalanced, where one class significantly outnumbers the other. In such cases, accuracy may not be an appropriate metric because it can be misleading.\n",
    "3. Define the Goal:Clearly define the primary goal of your model. Is it more critical to minimize false positives or false negatives? Does the problem require a balance between the two?\n",
    "4. Select Metrics:Choose metrics that align with your goal. Here are some common metrics and their use cases:\n",
    "\n",
    "        Accuracy: Appropriate for balanced datasets or when the cost of both false positives and false negatives is similar.\n",
    "        Precision: Useful when minimizing false positives is a priority (e.g., spam email detection).\n",
    "        Recall: Valuable when minimizing false negatives is a priority (e.g., medical diagnosis).\n",
    "        F1-Score: Balances precision and recall and is useful when there is a trade-off between false positives and false negatives.\n",
    "        Specificity: Relevant when the emphasis is on correctly identifying negative instances.\n",
    "        AUC-ROC: Useful for assessing discrimination power, especially when class imbalance exists.\n",
    "\n",
    "5. Use Multiple Metrics:Consider using multiple metrics to get a comprehensive view of model performance. Different metrics can provide insights into different aspects of the model's behavior.\n",
    "6. Consider Specific Domain Requirements:Some domains may have specialized metrics or fairness considerations, such as disparate impact analysis, equal opportunity, or demographic parity. These metrics can help assess and mitigate bias in model predictions.\n",
    "\n",
    "### Multiclass Classification vs. Binary Classification:\n",
    "\n",
    "1. Binary Classification: In binary classification, the task involves categorizing data into one of two possible classes or categories. For example, spam detection (spam or not spam) and disease diagnosis (disease present or absent) are common binary classification problems.\n",
    "\n",
    "2. Multiclass Classification: In multiclass classification, the task involves categorizing data into one of more than two possible classes. For example, classifying images of animals into categories like \"cat,\" \"dog,\" \"horse,\" \"elephant,\" etc., is a multiclass classification problem. Unlike binary classification, where the output is a binary decision (yes/no), multiclass classification assigns data points to one of several possible categories."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77fe0536-77a7-43cb-a30d-dc5a6787e5f7",
   "metadata": {},
   "source": [
    "# Q5. Explain how logistic regression can be used for multiclass classification."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a38f20-e807-44f8-8034-78dd0a3c40df",
   "metadata": {},
   "source": [
    "Logistic regression is primarily a binary classification algorithm, but it can be extended to handle multiclass classification problems through several strategies. Two common approaches for using logistic regression in multiclass classification are one-vs-all (OvA) and softmax regression (also known as multinomial logistic regression).\n",
    "\n",
    "### One-vs-All (OvA) or One-vs-Rest (OvR):\n",
    "\n",
    "1. In the OvA approach, you create a separate binary logistic regression classifier for each class. For a problem with \"k\" classes, you train \"k\" different binary classifiers.\n",
    "2. In each binary classifier, one class is treated as the positive class, while the rest of the classes are grouped into a single negative class.\n",
    "3. During prediction, you apply all \"k\" classifiers to the input, and the class associated with the classifier that produces the highest probability is the predicted class.\n",
    "\n",
    "For example, if we have a multiclass problem with three classes (A, B, and C), you would create three binary classifiers:\n",
    "\n",
    "    Classifier 1: Class A vs. (Class B, Class C)\n",
    "    Classifier 2: Class B vs. (Class A, Class C)\n",
    "    Classifier 3: Class C vs. (Class A, Class B)\n",
    "OvA is a simple and effective approach, but it may not be the most efficient for large numbers of classes, as it creates one binary classifier per class.\n",
    "\n",
    "### Softmax Regression (Multinomial Logistic Regression):\n",
    "\n",
    "1. Softmax regression is an extension of logistic regression that directly handles multiclass classification problems. It generalizes the logistic function to multiple classes.\n",
    "2. Instead of predicting a binary outcome (0 or 1) for each class, softmax regression predicts the probability of each class for a given input.\n",
    "3. The softmax function is used to normalize the scores of each class, ensuring that they sum to 1.\n",
    "4. During prediction, the class with the highest probability is chosen as the predicted class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "490886b4-81f0-4b48-b4af-5bf9a86b2019",
   "metadata": {},
   "source": [
    "# Q6. Describe the steps involved in an end-to-end project for multiclass classification."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f67e4c-1431-4990-b7aa-ae7bd7db47cc",
   "metadata": {},
   "source": [
    "An end-to-end project for multiclass classification involves a series of steps that take you from defining the problem to deploying a working model. Here's a comprehensive overview of these steps:\n",
    "\n",
    "1. Problem Definition: Clearly define the problem you want to solve with multiclass classification. Understand the specific objectives and requirements.\n",
    "2. Data Collection: Gather and collect the data that you will use to train and evaluate the multiclass classification model. Ensure the data is representative and relevant to the problem.\n",
    "3. Data Exploration: Perform exploratory data analysis (EDA) to understand the data's characteristics, including data distribution, class imbalances, and potential patterns.\n",
    "4. Data Preprocessing: Clean the data by handling missing values, outliers, and inconsistencies. Normalize or scale features as needed. Encode categorical variables into numerical representations, such as one-hot encoding or label encoding. Split the data into training and testing sets for model evaluation.\n",
    "5. Feature Engineering: Create new features, select relevant features, or transform existing features to improve model performance.\n",
    "6. Model Selection: Choose an appropriate algorithm for multiclass classification. Common choices include logistic regression, decision trees, random forests, support vector machines, and neural networks. Select a model that suits your problem's requirements and complexity.\n",
    "7. Model Training: Train the chosen model on the training data. Tune hyperparameters to optimize performance. Consider techniques like cross-validation to ensure robustness.\n",
    "8. Model Evaluation: Evaluate the model using appropriate multiclass classification metrics such as accuracy, precision, recall, F1-score, and the confusion matrix. Consider visualizing the results, including ROC curves if applicable.\n",
    "9. Model Tuning: Fine-tune the model by adjusting hyperparameters and features to achieve better performance. Re-train and re-evaluate the model as needed.\n",
    "10. Model Interpretability: If applicable, interpret the model's predictions and understand which features contribute to the classification decisions. Techniques like feature importance analysis or SHAP values can help.\n",
    "11. Model Deployment: Deploy the trained model to a production environment. This may involve using containerization technologies, creating APIs, or integrating the model into an existing application.\n",
    "12. Monitoring and Maintenance: Continuously monitor the model's performance in production. Implement regular updates and retraining as necessary to ensure it remains accurate and reliable.\n",
    "13. Documentation and Reporting: Document the entire project, including data sources, preprocessing steps, model details, and performance metrics. Prepare a report or presentation summarizing the project and its outcomes.\n",
    "14. Communication: Communicate the results and insights to stakeholders and collaborators, explaining the model's performance and any actionable insights it provides.\n",
    "15. Ethical Considerations: Address potential ethical issues such as bias, fairness, privacy, and data security throughout the project. Mitigate any ethical concerns associated with model predictions.\n",
    "16. Scaling and Optimization: If necessary, optimize the model for scalability and efficiency, especially in high-traffic or resource-constrained production environments.\n",
    "17. Feedback Loop: Establish a feedback loop to collect user feedback and performance data from the deployed model to identify areas for improvement and iterate on the model as needed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "193d5e4a-0910-49ad-9591-a636e3bbdd98",
   "metadata": {},
   "source": [
    "# Q7. What is model deployment and why is it important?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a57eb42-206d-4bf6-995e-3748b5e5247b",
   "metadata": {},
   "source": [
    "Model deployment is the process of taking a trained machine learning model and making it available for use in a production environment. In other words, it involves integrating the model into real-world applications, systems, or processes where it can make predictions or classifications on new, unseen data. Model deployment is a crucial step in the machine learning workflow, and its importance lies in several key aspects:\n",
    "\n",
    "1. Operationalization: Deployment transforms a machine learning model from a research or development project into a practical tool that can be used by end-users, businesses, or systems.\n",
    "2. Real-Time Predictions: It allows the model to provide real-time predictions or classifications, enabling immediate responses to new data inputs.\n",
    "3. Automation: Deployed models can automate decision-making processes, reducing the need for manual intervention in tasks such as fraud detection, recommendation systems, and image recognition.\n",
    "4. Scalability: Deployment facilitates scaling the model to handle large volumes of data and user requests. It ensures the model can handle the demands of production-level usage.\n",
    "5. Cost-Efficiency: By automating tasks and decision-making, model deployment can lead to cost savings and increased efficiency in various applications, such as customer support chatbots and predictive maintenance.\n",
    "6. Consistency: Deployed models provide consistent and standardized results, reducing variability in decision-making and ensuring that all users receive the same level of service.\n",
    "7. Improved Decision-Making: In applications like healthcare, finance, and manufacturing, model deployment can lead to more informed and data-driven decision-making.\n",
    "8. Feedback Loop: Deployed models can collect data and feedback on their predictions, enabling ongoing monitoring, model improvement, and adaptation to changing data distributions.\n",
    "9. Business Value: Model deployment can have a direct impact on a business's bottom line by enabling predictive analytics, personalization, and automation of critical processes.\n",
    "10. Competitive Advantage: Businesses that can effectively deploy and leverage machine learning models often gain a competitive advantage by offering more efficient and innovative solutions.\n",
    "11. Data Security and Privacy: Deploying models can be done in a secure and compliant manner, ensuring that sensitive data is handled appropriately and following data privacy regulations.\n",
    "12. Model Governance: Model deployment often includes the implementation of model governance and monitoring strategies to ensure models remain accurate and unbiased over time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f006caa2-e0a1-4b30-8c05-9e49fa9c97bc",
   "metadata": {},
   "source": [
    "# Q8. Explain how multi-cloud platforms are used for model deployment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e34ebff4-1d11-4d64-8c88-ef73e40dc599",
   "metadata": {},
   "source": [
    "Multi-cloud platforms are used for model deployment in machine learning to take advantage of multiple cloud service providers and their respective infrastructure, services, and capabilities. This approach offers several benefits, including redundancy, flexibility, and cost optimization. Here's an explanation of how multi-cloud platforms are used for model deployment:\n",
    "\n",
    "1. Redundancy and High Availability:Deploying machine learning models on multiple cloud platforms provides redundancy and high availability. If one cloud provider experiences downtime or issues, the model can fail over to another provider, ensuring that the service remains accessible.\n",
    "2. Geo-Distribution:Multi-cloud deployments allow models to be hosted in various geographic regions, reducing latency and ensuring users around the world have fast access to the service.\n",
    "3. Cost Optimization:Organizations can choose cloud providers and services that offer the most cost-effective solutions for their specific deployment requirements. This can help manage costs and take advantage of pricing differences between providers.\n",
    "4. Scalability:Multi-cloud platforms offer scalability and resource allocation flexibility. Depending on the cloud provider, deployment can be easily scaled up or down to accommodate varying workloads and demands.\n",
    "5. Vendor Lock-In Mitigation:Avoiding vendor lock-in is a significant advantage of multi-cloud deployments. It allows organizations to avoid relying too heavily on a single provider, reducing potential challenges if they decide to switch providers or use multiple providers simultaneously.\n",
    "6. Service Diversity:Different cloud providers offer various services, such as AI/ML platforms, data analytics tools, and DevOps solutions. Multi-cloud platforms allow organizations to choose the services that best fit their needs.\n",
    "7. Data and Regulatory Compliance:Compliance with data residency and regulatory requirements can be easier to achieve by hosting data and models in different cloud regions or providers as needed.\n",
    "8. Disaster Recovery and Backup:Multi-cloud deployments provide an effective disaster recovery strategy. Data and models can be backed up to one cloud provider while the primary deployment is hosted on another. This minimizes data loss and recovery time in case of a disaster.\n",
    "9. Load Balancing and Traffic Management:Multi-cloud platforms can use load balancing and traffic management strategies to distribute workloads effectively across multiple cloud providers, ensuring efficient resource utilization.\n",
    "10. Experimentation and Testing:Data scientists and engineers can use different cloud providers for experimentation and testing of models and deployment strategies. This provides a sandbox for exploring new ideas and approaches.\n",
    "11. Global User Base:Multi-cloud deployments are advantageous when serving a global user base. By leveraging cloud providers with a global presence, organizations can optimize user experiences and minimize latency.\n",
    "12. Security and Compliance:Multi-cloud platforms enable organizations to diversify security measures by combining security features and practices from different cloud providers, enhancing overall security and compliance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5308d0d3-a8d3-4107-8d6c-681694fcafc4",
   "metadata": {},
   "source": [
    "# Q9. Discuss the benefits and challenges of deploying machine learning models in a multi-cloud environment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aafe022-cb52-4740-be6d-d5d2db33994f",
   "metadata": {},
   "source": [
    "Deploying machine learning models in a multi-cloud environment offers various benefits, but it also presents certain challenges. Here, we'll discuss both the advantages and the difficulties associated with multi-cloud model deployments:\n",
    "\n",
    "### Benefits of Multi-Cloud Model Deployment:\n",
    "\n",
    "1. Redundancy and High Availability: Multi-cloud deployments provide redundancy and high availability. If one cloud provider experiences downtime or issues, the model can fail over to another provider, ensuring continuous service availability.\n",
    "\n",
    "2. Risk Mitigation: Using multiple cloud providers helps mitigate risks associated with vendor lock-in, ensuring flexibility in case of service or pricing changes.\n",
    "\n",
    "3. Geo-Distribution: Deploying models in different geographic regions reduces latency and ensures faster access for users worldwide.\n",
    "\n",
    "4. Scalability: Multi-cloud platforms offer scalability and resource allocation flexibility, allowing organizations to adapt to varying workloads efficiently.\n",
    "\n",
    "5. Cost Optimization: Organizations can choose cloud providers and services that offer the most cost-effective solutions for their specific deployment requirements, helping to manage costs.\n",
    "\n",
    "6. Service Diversity: Different cloud providers offer various services, such as AI/ML platforms, data analytics tools, and DevOps solutions. Multi-cloud deployments allow organizations to choose the services that best fit their needs.\n",
    "\n",
    "7. Data and Regulatory Compliance: Multi-cloud deployments make it easier to achieve compliance with data residency and regulatory requirements by hosting data and models in different cloud regions or providers as needed.\n",
    "\n",
    "### Challenges of Multi-Cloud Model Deployment:\n",
    "\n",
    "1. Complexity: Managing multi-cloud deployments is complex and requires a robust strategy and architecture. It can be challenging to ensure seamless operations and consistent security practices across multiple providers.\n",
    "\n",
    "2. Interoperability: Different cloud providers may have varying APIs, toolsets, and service offerings, making it challenging to ensure interoperability and smooth integration between services.\n",
    "\n",
    "3. Data Transfer Costs: Transferring data between cloud providers can be costly and time-consuming, particularly for large datasets. Data egress fees can add up quickly.\n",
    "\n",
    "4. Data Consistency: Maintaining data consistency across different cloud providers can be a challenge, especially when dealing with distributed data storage.\n",
    "\n",
    "5. Security and Compliance: Ensuring consistent security and compliance practices across multiple cloud providers is a complex task. It requires managing a diverse set of security features and practices.\n",
    "\n",
    "6. Technical Expertise: Operating in a multi-cloud environment may require a higher level of technical expertise, as each cloud provider may have unique features and management tools.\n",
    "\n",
    "7. Resource Fragmentation: Resources, such as compute, storage, and networking, may become fragmented across providers, leading to inefficient resource utilization.\n",
    "\n",
    "8. Cost Management: Managing costs effectively across multiple providers can be challenging. It's essential to monitor usage and expenses to avoid unexpected charges.\n",
    "\n",
    "9. Governance and Policy Enforcement: Implementing governance and policy enforcement consistently across providers can be complex. It's crucial to define and enforce standardized practices.\n",
    "\n",
    "Vendor Management: Dealing with multiple cloud providers requires maintaining relationships, contracts, and service-level agreements with each, which can be resource-intensive.\n",
    "\n",
    "Migration and Portability: Migrating models and data between cloud providers or back to on-premises infrastructure can be complex, requiring careful planning and execution."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
